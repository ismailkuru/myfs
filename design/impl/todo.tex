\section{Направления дальнейшей работы}

\label{sec:todo}

В текущей реализации myfs отсутствует ряд важных функций для файловой системы,
кроме этого имеется ряд проблем которые требуют решения. В этом разделе
уделяется внимание этим проблемам и возможным способам их решения.


\subsection{Отслеживание свободного/занятого места на диске}

На данный момент myfs алоцирует место на диске в режиме append-only, т. е.
блоки диска просто алоцируются по порядку. Когда доступное место будет исчерпано
myfs не сможет продолжать работу.

Проблема с отслеживанием свободного/занятого места с использованием COW структур
данных заключается в том, что чтобы сохранить изменения в этой структуре на диск
необходимо алоцировать место на диске, что в свою очередь вновь приведет к
очередному изменению структуры данных.

Проблема может быть решена несколькими способами. Один из способов заключается
в резервировании небольшого участка дискового пространства, в который может быть
сохранена часть информации о свободном/занятом месте на диске. Например, в myfs
можно зарезервировать место для этого прямо в структуре контрольной точки. При
создании контрольной точки информация о свободном/занятом месте диске должна
быть выписана на диск, что в свою очередь потребует алокации/освобождения места
на диске. Информация об этих алокациях и освобождениях сохраняется в памяти и
в выделенное место на диске.

Недостаток такого подхода заключается в том, что ограничение на количество
информации, которую потребуется сохранить заранее может быть не известно, а,
соответственно, придется принимать дополнительные меры для того, чтобы уменьшить
объем сохраняемой информации, чтобы она вместилась в зарезервированный участок
дискового пространства.

На самом деле нет необходимости явно заранее резервировать место на диске
достаточно предусмотреть в структуре контрольной точки место под указатель на
некоторое место на диске и алоцировать его динамически. Более того это место
можно использовать в качестве WAL и уменьшить количество информации выписываемой
на диск в процессе сохранения контрольной точки о чем будет рассказано далее.


\subsection{Журналирование}

При использовании LSM-деревьев чтобы создать контрольную точку может
потребоваться прочитать с диска до 4 Mb (2 Mb на $C_2$ inode\_map и dentry\_map)
и выписать на диск возможно даже больше. Это не было бы проблемой если принятие
решения о создании контрольной точки всегда оставалось за драйвером файловой
системы. Однако пользователям файловой системы иногда может потребоваться
зафиксировать состояние всей файловой системы или состояние отдельных
файлов/каталогов на диске. В случае если приложение часто иницирует такие
операции скорость работы этого приложения как и скорость работы всей файловой
системы может пострадать.

Для того чтобы частично справится с проблемой необходимо постараться избежать
выполнения операции flush над LSM-деревьями при создании контрольной точки
файловой системы. Один из вариантов добиться этого это использовать WAL.

LSM-деревья обладают некоторой формой свойства идемпотентности. Т. е. если взять
любой суффикс последовательности операций над LSM-деревом и повторить эти
операции, то логическое состояние LSM-дерева не должно измениться при корректной
реализации. Таким образом в качестве WAL для LSM-дерева может выступать простая
последовательность добавленных в LSM-дерево ключей.

Идея использования WAL заключается в том, что все вставки в LSM-дерево
составляющие одну операцию над файловой системой сначала производятся над WAL
и только после завершения они выполняются над LSM-деревьями. WAL выписывается на
диск по мере заполнения так, чтобы объем информации хранящийся в памяти был
ограничен. При создании контрольной точки необходимо выписать только хранящуюся
в памяти часть WAL, но не требуется выполнять операцию flush над деревьями. При
монтировании файловой системы драйвер проверяет сохраненный на диске WAL и
проигрывает его, т. е. добавляет элементы из WAL в соответствующие LSM-деревья.

Журнал может быть удален после того как все ключи в журнале попали в LSM-деревья
и были записаны на диск как часть LSM-дерева и такое состояние было
зафиксировано в контрольной точке.

Кроме того журнал может быть использован для того чтобы решить проблему с
отслеживанием свободного/занятого места на диске рассмотренную ранее.


\subsection{Отложенное удаление inode}

Стандарт POSIX предусматривает следующее стандартное поведение при удалении
файла. Если какой-то из процессов держит файловый дескриптор ссылающийся на
удаляемый файл, то для этого процесса файл должен быть полностью доступен для
выполнения всех операций, которые разрешены процессу.

Такое поведение может показаться не логичным, однако оно нашло свои применения.
Например, распространенная идиома в Unix-подобных системах для создания
временных файлов работает следующим образом:
\begin{enumerate}
  \item создать и открыть новый файл;
  \item вызвать unlink, чтобы удалить этот файл из каталога;
  \item работать с открытым файловым дескриптором;
  \item закрыть файловый дескриптор, когда файл больше не нужен.
\end{enumerate}

Благодаря тому, что для файла все еще существует открытый файловый дескриптор
и физическое освобождение места занятое файлом будет отложено до закрытия
файлового дескриптора, идиома описанная выше работает.

Чтобы поддержать отложенное удаление файла достаточно сохранить номер inode-а
файла, на который не осталось ссылок из dentry\_map. Для этого можно
использовать еще одно LSM-дерево. Это дерево в обычных условиях не должно
становится большим и скорее всего будет помещаться в память, а при не аварийном
завершении работы файловой системы это дерево должно быть пустым.
завести еще одно LSM-дерево.


\subsection{Коллизии хешей имен файлов}

Как объяснялось ранее при выполнении операции readdir в качестве смещения
используется 32-битный хеш имени файла/каталога. При довольно распространенном
ограничении в 256 байт на имя файла/каталога коллизии неизбежны. Соответственно,
если хеш используется, чтобы закодировать позицию в некотором каталоге, то при
наличии коллизий хеш не определяет позицию однозначно.

Для решения проблемы можно использовать несколько вариантов. Проблему можно
сделать гораздо менее вероятной, если использовать 64-битные значения хеша.
Например, так поступили в файловой системе ext4 в Linux Kernel. Существенное
достоинство такого решения заключается в простоте реализации.

Другой способ решения проблемы, который используется например в ZFS, создать
дополнительный индекс для выполнения операции readdir. В этом индексе необходимо
поддерживать файлы/каталоги внутри каталога упорядоченными по номеру их inode.
Так как внутри файловой системы номера inode всех файлов/каталогов уникальны,
то номер inode может служить в качестве смещения внутри каталога без коллизий.


\subsection{Поддержка больших файлов}

В текущей реализации myfs информация о размещении файла на диске представляется
в виде простого массива. Каждый элемент массива содержит смещение в файле и
смещение на диске и описывает блок размером в одну страницу файловой системы.
Такой подход не работает для больших файлов по нескольким причинам.

Например, уже для файла размером в 1 Mb и размере страницы в 4 Kb потребуется
256 элементов в массиве. Чтобы сохранить 256 элементов требуется 4Kb дискового
пространства. Так как inode содержащий эту информация хранится в LSM-дереве то
такой inode будет занимать много места в памяти пока будет хранится в $C_0$ или
$C_1$.

Хранение такого inode на диске как часть LSM-дерева также создает некоторые
неудобства. При выполнении операции слияния inode будет читаться и выписываться,
и размер inode-ов будет влиять на размер индекса и время выполнения операций
слияния.

Таким образом хотелось бы избежать хранения потенциально неограниченных по
размеру данных в LSM-дереве, а вместо этого хранить ссылку на место на диске,
где эти данные хранятся, или хранить эту информацию отдельно от inode.

Для достижения этих целей можно использовать несколько способов. Первый способ
заключается в том, чтобы создать отдельное LSM-дерево для хранения информации
о расположении содержимого файла на диске. В качестве ключа в этом LSM-дереве
может выступать номер inode и смещение внутри файла, в качестве значения может
использовать смещение на диске и возможно дополнительные данные, такие как
размер, контрольная сумма и прочее. Очевидным недостатком такого подхода
является то, что все файлы будут использовать общее LSM-дерево, которое станет
дополнительным источником синхронизации.

Чтобы продемонстрировать другой недостаток этого подхода проведем небольшой
эксперимент. Используя скрипт из раздела~\ref{sec:lsmlev} найдем средний размер
файла в файловой системе. На машине автора средний размер файла порядка 64 Kb.
Более того из порядка полумиллиона файлов в файловой системе автора более
половины имеют размер меньший или равный 4 Kb. Таким образом большинство файлов
являются довольно маленькими и объем информации необходимый для того, чтобы
описать расположение таких файлов на диске очень мал. Но если информация об их
расположении на диске будет хранится только в едином индексе доступ к ней будет
одинаково медленным для всех файлов.

Вместо использования единого индекса для всех файлов можно использовать
отдельный индекс для каждого файла. Этот индекс может выглядеть, например, как
цифровое или базисное дерево (RadixTree). В силу того, что структура является
деревом, она хорошо подходит для использования COW и позволяет поддерживать
разреженные файлы. Корень этого такого дерева будет иметь небольшой
фиксированный размер и может быть сохранен прямо в структуре inode. Высота
такого дерева определяется логическим размером файла и для маленьких файлов
достаточно хранить ссылку на содержимое файла на диске в корне.
